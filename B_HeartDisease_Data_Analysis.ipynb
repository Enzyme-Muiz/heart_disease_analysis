{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:60px;\"><b>HeartDisease_Data_Analysis</b></h1></center>\n",
    "<b>This notebook reads in the HeartDisease data and preprocess the data further. It then performs some statistical analysis on the data. Some machine learning algorithm such as Random forest, Deep Neural Network, logistic regression and kNN are also used to model the data.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Import packages</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency, shapiro, ttest_ind, ks_2samp, mannwhitneyu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dython import nominal\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    matthews_corrcoef,\n",
    "    plot_roc_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Read data, clean </b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Heart_disease.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Diabetic and Race are categorical variables with more than two levels\n",
    "expand_df = pd.get_dummies(df, columns=[\"Diabetic\", \"Race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_df = expand_df.rename(\n",
    "    columns={\n",
    "        \"Diabetic_No, borderline diabetes\": \"DiabeticBorderline\",\n",
    "        \"Diabetic_Yes (during pregnancy)\": \"DiabeticYesPregnancy\",\n",
    "        \"Race_American Indian/Alaskan Native\": \"RaceAmericanIndianAlaskanNative\",\n",
    "        \"Race_Asian\": \"RaceAsian\",\n",
    "        \"Race_Black\": \"RaceBlack\",\n",
    "        \"Race_Hispanic\": \"RaceHispanic\",\n",
    "        \"Race_Other\": \"RaceOther\",\n",
    "        \"Race_White\": \"RaceWhite\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Input</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###this is the feature to be used as y_of_model\n",
    "###\"Stroke\" \"HeartDisease\" \"DeadorAlive\"\n",
    "###if y_of_model is \"DeadorAlive\" declare a subsetting variable\n",
    "y_of_model = \"HeartDisease\"\n",
    "subset_variable = \" \"  ##\"HeartDisease\" \"Stroke\" or \"\"\n",
    "if y_of_model == \"DeadorAlive\":\n",
    "    df = df.loc[df[subset_variable] == \"Yes\"]\n",
    "    expand_df = expand_df.loc[expand_df[subset_variable] == \"Yes\"]\n",
    "else:\n",
    "    print(\"nothing to subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Statistical Analysis</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###category_vs_category\n",
    "##'HeartDisease' removed from the other categorical_features\n",
    "categorical_features = [\n",
    "    \"HeartDisease\",\n",
    "    \"Smoking\",\n",
    "    \"Diabetic\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"Sex\",\n",
    "    \"Race\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\",\n",
    "    \"DeadorAlive\",\n",
    "]\n",
    "categorical_features.remove(y_of_model)\n",
    "for feature in categorical_features:\n",
    "    chisqt = pd.crosstab(eval(\"df.\" + y_of_model), eval(\"df.\" + feature), margins=True)\n",
    "    value = np.array(\n",
    "        [\n",
    "            chisqt.iloc[0][0 : (chisqt.shape[1] - 1)].values,\n",
    "            chisqt.iloc[1][0 : (chisqt.shape[1] - 1)].values,\n",
    "        ]\n",
    "    )\n",
    "    print(feature + \" results:\" + str(chi2_contingency(value)[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####category_vs_continuous(and count data)\n",
    "continous_and_count_data = [\"BMI\", \"SleepTime\", \"PhysicalHealth\", \"MentalHealth\"]\n",
    "for continuous_or_count in continous_and_count_data:\n",
    "    NO_y_of_model = df.loc[df[y_of_model] == \"No\", continuous_or_count]\n",
    "    YES_y_of_model = df.loc[df[y_of_model] == \"Yes\", continuous_or_count]\n",
    "    if (\n",
    "        shapiro(np.array(eval(\"df.\" + continuous_or_count)))[1] <= 0.05\n",
    "    ) == True:  # normality check\n",
    "        print(\n",
    "            \"non-parametric results for \"\n",
    "            + continuous_or_count\n",
    "            + \" \"\n",
    "            + str(ks_2samp(NO_y_of_model, YES_y_of_model)[1])\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"parametric results for \"\n",
    "            + continuous_or_count\n",
    "            + \" \"\n",
    "            + str(ttest_ind(NO_y_of_model, YES_y_of_model, equal_var=False)[1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####categorical_vs_ordinal\n",
    "ordinal_data = [\"AgeCategory\", \"GenHealth\"]\n",
    "for ordinal_feature in ordinal_data:\n",
    "    NO_y_of_model = df.loc[df[y_of_model] == \"No\", ordinal_feature]\n",
    "    YES_y_of_model = df.loc[df[y_of_model] == \"Yes\", ordinal_feature]\n",
    "    res = mannwhitneyu(x=NO_y_of_model, y=YES_y_of_model, alternative=\"two-sided\")[1]\n",
    "    print(ordinal_feature + \" result: \" + str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Preprocessing for machine learning</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_of_model != \"DeadorAlive\":\n",
    "    expand_df = expand_df.drop(columns=[\"DeadorAlive\"])\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"HeartDisease\",\n",
    "    \"Smoking\",\n",
    "    \"AlcoholDrinking\",\n",
    "    \"Stroke\",\n",
    "    \"DiffWalking\",\n",
    "    \"PhysicalActivity\",\n",
    "    \"Asthma\",\n",
    "    \"KidneyDisease\",\n",
    "    \"SkinCancer\",\n",
    "]\n",
    "try:\n",
    "    categorical_features.remove(y_of_model)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    categorical_features.remove(subset_variable)\n",
    "except:\n",
    "    pass\n",
    "for feature in categorical_features:\n",
    "    expand_df[feature] = expand_df[feature].replace([\"No\", \"Yes\"], [0, 1])\n",
    "\n",
    "expand_df[\"Sex\"] = expand_df[\"Sex\"].replace([\"Male\", \"Female\"], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####downsampling:\n",
    "expand_df_yes = expand_df[expand_df[y_of_model] == \"Yes\"]\n",
    "expand_df_no = expand_df[expand_df[y_of_model] == \"No\"]\n",
    "expand_df_no_downsample = resample(\n",
    "    expand_df_no, replace=True, n_samples=len(expand_df_yes), random_state=42\n",
    ")\n",
    "expand_df_downsampled = pd.concat([expand_df_no_downsample, expand_df_yes])\n",
    "try:\n",
    "    expand_df_downsampled = expand_df_downsampled.drop(subset_variable, axis=1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####standardscaling of continuous and count variables\n",
    "continous_and_count_data_and_ordinal = [\n",
    "    \"BMI\",\n",
    "    \"SleepTime\",\n",
    "    \"PhysicalHealth\",\n",
    "    \"MentalHealth\",\n",
    "    \"AgeCategory\",\n",
    "    \"GenHealth\",\n",
    "]\n",
    "for candcount in continous_and_count_data_and_ordinal:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(expand_df_downsampled[[candcount]])\n",
    "    expand_df_downsampled[[candcount]] = scaler.transform(\n",
    "        expand_df_downsampled[[candcount]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_df = expand_df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_df[y_of_model] = expand_df[y_of_model].replace([\"No\", \"Yes\"], [0, 1])\n",
    "y = expand_df[[y_of_model]]\n",
    "X = expand_df.drop(y_of_model, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.09, random_state=0, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Random Forest</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print model and matthews_corrcoef scores (-1, 0, +1)\n",
    "name_of_model = \"RandomForestClassifier\"\n",
    "res_list = []\n",
    "print(\"max_features-max_depth-n_estimators-MCC-accuracy\")\n",
    "for x in [10, 15, 20]:\n",
    "    for j in [20, 25, 30, 35]:\n",
    "        for w in [20, 40, 80, 100]:\n",
    "            clf = RandomForestClassifier(\n",
    "                n_estimators=w,\n",
    "                criterion=\"entropy\",\n",
    "                max_depth=j,\n",
    "                max_features=x,\n",
    "                n_jobs=4,\n",
    "            )\n",
    "            clf = clf.fit(X_train, eval(\"y_train.\" + y_of_model + \".ravel()\"))\n",
    "            y_pred = clf.predict(X_test)\n",
    "            res = (\n",
    "                str(x)\n",
    "                + \"-\"\n",
    "                + str(j)\n",
    "                + \"-\"\n",
    "                + str(w)\n",
    "                + \"-\"\n",
    "                + str(matthews_corrcoef(y_test, y_pred))\n",
    "                + \"-\"\n",
    "                + str(accuracy_score(y_test, y_pred))\n",
    "            )\n",
    "            print(res)\n",
    "            res_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(y_of_model + \" risk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[::, 1]\n",
    "fpr, tpr, _ = roc_curve(eval(\"y_test.\" + y_of_model + \".ravel()\"), y_pred_proba)\n",
    "auc_result = str(round(auc(fpr, tpr), 2))\n",
    "plt.fill_between(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"green\",\n",
    "    alpha=0.5,\n",
    "    label=\"{} ({})\".format(name_of_model, auc_result),\n",
    ")\n",
    "plt.plot(fpr, tpr)\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.title(\"ROC of {} ({})\".format(name_of_model, y_of_model))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Deep Neural Network</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(\n",
    "    Dense(len(eval(\"y_train.\" + y_of_model + \".unique()\")) - 1, activation=\"sigmoid\")\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=13,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X,\n",
    "    eval(\"y.\" + y_of_model + \".ravel()\"),\n",
    "    epochs=40,\n",
    "    callbacks=[es],\n",
    "    validation_split=0.09,\n",
    "    batch_size=10,\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"accuracy\"], label=\"training\")\n",
    "plt.plot(history[\"val_accuracy\"], label=\"validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>Logistic Regression</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log, X_test_log = train_test_split(\n",
    "    expand_df_downsampled, test_size=0.09, random_state=0, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = list(X_train_log.columns)\n",
    "independent_variables.remove(y_of_model)\n",
    "formular = y_of_model + \" ~ \"\n",
    "for feature in independent_variables:\n",
    "    formular = formular + \" + \" + feature\n",
    "formular = formular.replace(\"+\", \"\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit(formular, data=X_train_log)\n",
    "model = model.fit_regularized(start_params=None, method=\"l1\", alpha=0)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_odds = pd.DataFrame(np.exp(model.params), columns=[\"OR\"])\n",
    "model_odds[\"z-value\"] = model.pvalues\n",
    "model_odds[[\"2.5%\", \"97.5%\"]] = np.exp(model.conf_int())\n",
    "\n",
    "print(model_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_ratio = model_odds[model_odds[\"z-value\"] <= 0.99].sort_values(\"OR\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=odd_ratio[\"OR\"], y=odd_ratio.index)\n",
    "plt.xlabel(\"OddRatio\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.axvline(1)\n",
    "plt.title(y_of_model + \" OddRatio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(exog=X_test_log[independent_variables])\n",
    "accuracy_score(y_true=list(X_test_log[y_of_model]), y_pred=list(round(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:60px;\"><b>KNN</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for k in range(2, 50):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, p=1)\n",
    "    clf = clf.fit(X_train, eval(\"y_train.\" + y_of_model + \".ravel()\"))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    res = str(k) + \"-\" + str(matthews_corrcoef(y_test, y_pred))\n",
    "    print(res)\n",
    "    res_list.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
